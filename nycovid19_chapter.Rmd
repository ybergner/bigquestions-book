# NYC COVID-19 Data

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=TRUE, warning=FALSE, message=FALSE)
```

## Prologue {-}

Although Madonna may have called COVID-19 [the great equalizer](https://pagesix.com/2020/03/22/madonna-calls-coronavirus-the-great-equalizer-in-bizarre-bathtub-video/), others have highlighted some data that suggest the opposite may be true. As before, when we acknowledge the range of human experience, in the case of disease as in other cases, variance in outcomes does not necessarily imply systematic unfairness. For example, if COVID-19 is more fatal for elderly adults, as it appears to be, this is not something we would label as obviously unfair. Everyone gets old, and physical deterioration unfortunately comes with the territory. Certain chronic health conditions make people more vulnerable to COVID-19, but some of those conditions might just be the result of bad luck. We can try to make a world in which everyone has comparable access to healthcare, but we probably still can’t make a world in which everyone has the same health outcomes.

However, consider the following headlines:

+ [Why African-Americans may be especially vulnerable to COVID-19](https://www.sciencenews.org/article/coronavirus-why-african-americans-vulnerable-covid-19-health-race)

+ [Coronavirus Numbers Reflect New York City’s Deep Economic Divide](https://theintercept.com/2020/04/09/nyc-coronavirus-deaths-race-economic-divide/)

+ [In NYC, 'stark contrast' in COVID-19 infection rates based on education and race](https://abcnews.go.com/Health/nyc-stark-contrast-covid-19-infection-rates-based/story?id=69920706)

+ [Who gets hospitalized for Covid-19? Report shows differences by race and sex](https://www.statnews.com/2020/04/09/hospitalized-covid-19-patients-differences-by-race-and-sex/)

When adverse health outcomes are associated with income, race, and/or sex, we are much more likely to cry foul than when they are associated with age or pre-existing chronic conditions. Part of this has to do with the difference between variance among individuals, which is an unavoidable fact of life, and variance between certain classes or groups. These media reports are all suggesting that COVID-19 may not be affecting all groups with the same severity. What exactly does that mean, and is it evidence of unfairness?

New York City has emerged as the epicenter of the US outbreak, claiming over 14,000 lives as of the time of this writing. As specific data have become available, researchers and reporters have examined counts of coronavirus infections and/or deaths by zip code and borough, by age, sex, and race. In this chapter, we will take a closer look at the data and the media reports.

Some additional reports on Coronavirus in New York:

+ [COVID-19 Cases in New York City, a Neighborhood-Level Analysis](https://furmancenter.org/thestoop/entry/covid-19-cases-in-new-york-city-a-neighborhood-level-analysis)
+ [Coronavirus Statistics: Tracking The Epidemic In New York](https://gothamist.com/news/coronavirus-statistics-tracking-epidemic-new-york)




## Part 1: COVID NYC

On April 10, 2020, [ABC News](https://abcnews.go.com/Health/nyc-stark-contrast-covid-19-infection-rates-based/story?id=69920706) covered an online report (by the NYU Furman Center) that examined cases of COVID-19 in New York City on a neighborhood level. Most COVID-19 data that had been coming out had been reporting on the city as a whole. The main idea here was that neighborhoods tell a different story. Data scientist call this a shift in the unit-of-analysis. The city is made of boroughs, which themselves are made up of smaller neighborhoods. So the unit of analysis could be the whole city, the boroughs of the city, or something even more fine-grained, like neighborhoods or zipcode areas. For example, some zipcodes are wealthier and some poorer. Zipcode areas also vary by racial composition. If we examine COVID-19 outcomes by neighborhood, we may be able to see patterns and associations between disease incidence and race or socio-economic variables. Indeed, the Furman Center found such associations. The ABC News report produced images like the following:

![](images/abc_COVID19NycZip_v03_KA_hpEmbed_17x12_992.jpg) 

People familiar with the layout of New York City might be able to identify low-income and largely African-American neighborhoods like Hunts Point in the South Bronx.  ABC News produced a corresponding map showing the share of adults with college degree, a measure of educational attainment which the Furman Center report said was associated with disease incidence.

![](images/abc_CollegeDegreeNycZip_v02_KA_hpEmbed_17x12_992.jpg)

It requires switching back and forth between these images, but the dark regions on the COVID map (higher rates of disease) seem to often correspond to the lighter regions on the college degree map (lower college share). In other words, areas with lower educational attainment seem to have higher rates of the disease. There are many possible explanations of this relationship, which are discussed in the Furman report and elsewhere.
 
How does one make these data visualizations? And are they the best way to "see" the signals in the data?

ABC News also reproduced a version of table below, showing racial composition by neighborhood. The title may confuse matters, however. In this table, multiple neighborhoods (zipcodes) are actually grouped together into five sets using **quintiles.** You take all of the zipcodes, rank-order them by COVID-19 concentration, and then select the bottom fifth, the next fifth, and so on up to the top fifth. These groups are labeled "lowest concentration", "low concentration", and so on up to "highest concentration."

Technically, the quintiles are the cut-points, so for five groups, there are four quintiles. If you look at the table below, the cut-points/quintiles are {3.33, 4.13, 4.77, 5.87}. Of course, this division process can be done for a different number of **quantiles**--note the spelling--not necessarily five. A division of three groups is made by choosing two (cut-point) tertiles or terciles. The median is the 2-quantile, as it is the cut-point that divides a data set into two equal parts. Unfortunately, the naming conventions here are rather confusing, but you get used to them if you use them a lot.

![](images/abc_COVID19RacialComp_v02_KA_hpEmbed_37x16_992.jpg)

If you look at the table above, you may notice trends or patterns between racial composition (of these groups of neighborhoods) and COVID-19 concentration. The trends are not perfectly linear. But, for example, the proportion of Black and Hispanic people in the low-concentration neighborhoods is 37.3%. While in the high concentration neighborhoods, this combined share is 55.6%.

In the remainder of this tutorial, we will examine how to recreate graphs and tables like the one above from publicly available data. This will enable you to create your own versions or update the ones above with new data. We will also look at alternative representations and at some simulation-based tests to see how likely it is that such disparities might occur by chance.

Let's begin!

### Getting some data {-}

In this tutorial, I will walk you through the steps of creating some of the figures and tables that go into media reports about COVID-19 outcomes. The examples here are all NYC-centric, but the methods, especially for US Census data, are completely general. The hardest part of all of this--and this is generally true about the practice of data science--is getting all of the data from different sources cleaned up and fitted together.


### Local data on COVID from the city and/or state {-}

For state and municipality-level COVID-19 data in New York, these are some sources:

+ https://www1.nyc.gov/site/doh/covid/covid-19-data-archive.page
+ https://github.com/nychealth/coronavirus-data
+ https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53e

These sources are updated daily. I will be working with the GitHub data as of April 23. This is actually two weeks later than the Furman/ABC reports, so more up-to-date. I downloaded the files from the online repository and put them into a folder on my computer. For example, here I will load and view the borough-level data table. 

```{r}
nyc_boro_data <- read.csv("data/coronavirus-nyc/boro.csv", stringsAsFactors = F)
nyc_boro_data
```

According to the documentation in the GitHub README file (a valuable source of information), this table contains rates of confirmed cases, by NYC borough of residence. Rates are:

+ Cumulative since the start of the outbreak
+ Age adjusted according to [the US 2000 standard population](https://www.cdc.gov/nchs/data/statnt/statnt20.pdf)
+ Per 100,000 people in the borough

What does age-adjusted rate mean? You can read the link, but the main idea here is to try to put all of the boroughs on equal footing in the rate per 100,000 people, even if some boroughs have an older or younger population than others. Which it turns out they do. Later, once we have borough populations, we could examine simple population-adjusted rates that are not age-adjusted and see what those look like in comparison.

If we wanted to do age-adjustment, or even simpler population adjustment, we would need to supplement this COVID data with population data, for example obtained from the US Census. Before we turn to that, let us just quickly explore the other data provided by NYC.

```{r}
nyc_sex_data <- read.csv("data/coronavirus-nyc/by-sex.csv")
nyc_sex_data
```

(By the way, you may get a warning like, "incomplete final line found" when reading this file. You can ignore it. R is expecting each line in a .csv file to end with a newline/return. You can also just open the file and add that newline after the last row if you like). 

Case and fatality rates by sex show that males are being infected and dying at significantly higher rates. Note that each of these is already adjusted to rate per 100,000.

```{r}
nyc_age_data <- read.csv("data/coronavirus-nyc/by-age.csv")
nyc_age_data
```

Age-level data show a few interesting features. For one, children are barely even getting infected. Among adults, infection rates are slightly higher for older adults, but death rates are much higher. We could derive a measure of case fatality rate (CFR) as follows:

```{r}
nyc_age_data$CFR <- round(nyc_age_data$DEATH_RATE/nyc_age_data$COVID_CASE_RATE, 3)
nyc_age_data
```

From this we see that adults 75 and older have a `r paste0(nyc_age_data$CFR[5]*100,"%")` chance of dying from COVID-19, compared to a `r paste0(nyc_age_data$CFR[3]*100,"%")` for adults between 45-64.


**Exercise**: compute the case fatality rate by sex.

The most captivating data set provided by the city (hence the images we started out with) is probably the zipcode-level data, the first few rows of which look like this:


```{r}
nyc_zipcode_data <- read.csv("data/coronavirus-nyc/tests-by-zcta.csv")
head(nyc_zipcode_data,20)
```

Notice that the first row is missing a zipcode. Presumably these are COVID tests for which we do not know where the people who were tested actually reside.

For each other row, we have a zipcode, the number of positive tests, the number of total tests, and the percent positive.

**Exercise**: Which of these expressions should give the percent positive tests

+ `nyc_zipcode_data$Total/nyc_zipcode_data$Positive*100`
+ `nyc_zipcode_data$Positive/nyc_zipcode_data$Total`
+ `nyc_zipcode_data$Positive/nyc_zipcode_data$Total*100`
+ `(nyc_zipcode_data$Total-nyc_zipcode_data$Positive)`
+ `(nyc_zipcode_data$Total-nyc_zipcode_data$Positive)*100`


Now you might want to keep the first row, the one with the missing zipcode, in your data. But I would rather remove it now, because I'm going to try to add information to this zipcode table down the line. While I'm at it, I will also rename the column "MODZCTA" with "zipcode."


```{r}
nyc_zipcode_data <- na.omit(nyc_zipcode_data)
names(nyc_zipcode_data)[1] <- "zipcode"
head(nyc_zipcode_data)
```

There are a couple more tables included in the GitHub repository, for example ones showing the daily tracking of new cases, hospitalizations, and deaths. But as we are focusing on the neighborhood level counts, I will leave them out of these notes. 

In the next part of the series, we will get started with US Census data.


## Part 2: Getting started with US Census data

To get census data, you can go to (https://data.census.gov/), but be warned: it is a big maze and not that easy to navigate. What the pros who make media reports do (probably) is use the US Census API to make specific requests for data. If you use it a lot, you will need an API key. This is easy enough to get, but you need to [request one here](https://api.census.gov/data/key_signup.html). Once you have a key, you can declare it in your R code or, better for security/code-sharing, embed it in a .Renviron file. 

Here I will load the `censusapi` package (and also `dplyr` while I'm at it), and load my key. You can modify this line with your key. If you don't have one, some or all of the code below will still work if you comment out the `key=myKey`. Without an API key, however, there is a limit to the size and number of queries per IP address.

```{r include = FALSE}
myKey <- "6347985e12e867b7c72ed972da2836238502657d"
```

```{r}
library(censusapi)
library(dplyr)
# comment this out if you want to proceed without a key
# myKey = Sys.getenv("CENSUS_KEY") #store your key in .Renviron
```


More importantly, when it comes to census data, you need to know what you're asking for. That means you need to know which data sets, which variables, which geographic units, etc. A brief introductory [API users guide can be found here](https://www.census.gov/content/dam/Census/data/developers/api-user-guide/api-guide.pdf). It's 20 pages long. You can just follow along here if you want some examples.

We will be interested in the [American Community Survey 5-Year data](https://www.census.gov/data/developers/data-sets/acs-5year.html) (aka ACS5) which provides estimates aggregated over a 5-year period, revisited every two years. The last published data set, i.e., the most current one available, is from 2018.

### Census Variables {-}

There are something like 20,000 variables available in ACS, and these can be retrieved through queries invidividually or in groups. Some useful groups for our analysis are the following

+ B01001	SEX BY AGE	
  + This has a lot of subcategories, such as Male 5-9 Years, Male 10-14 years, etc.
+ B02001	RACE (disregards Hispanic or Latino Origin)	
+ B03002	HISPANIC OR LATINO ORIGIN BY RACE	
+ B19013	MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS

For each group, a list of variables can be found on a corresponding census.gov website. For example, to find the variables in the SEX BY AGE group, you can go to https://api.census.gov/data/2018/acs/acs5/groups/B01001.html (notice the URL ending is the same as the group). There you will find variables such as

+ B01001_001E	Estimate!!Total
+ B01001_002E	Estimate!!Total!!Male
+ B01001_026E	Estimate!!Total!!Female

And many more. Variables that end in E are estimates. For each one there is often a margin of error, which is the same code ending in M instead of E. Finally for both estimates and margins of error, there may be annotations (e.g. B01001_002EA and B01001_002MA), if these numbers are missing or not straightforward. Details about annotation meanings can be found [here](https://www.census.gov/data/developers/data-sets/acs-1year/notes-on-acs-estimate-and-annotation-values.html). This is just an overview of what the ACS5 variable names look like.

### Geography Units {-}

Census data are available at many levels related to geographical units. The smallest unit is called a census "block" and typically covers between 600 and 3000 people. A collection of blocks forms a census tract (2500 to 8000 people). But US states are also divided into counties, and both state and county identifiers can be used as region selectors. Note that to use the Census API, one has to use numerical identifiers for states and counties. For example, the borough of Brooklyn is actually Kings County, New York, which is county 047 in state 36. And yes, you have to include all three digits, including the leading zero, to identify individual counties. Zipcode tabulation areas (aka ZCTA) is another option, wherein you specify the five-digit zip code. We will want to use that, because NYC provided COVID-19 testing data at the zipcode level. 

#### Borough-level data {-}

First, let's retrieve some data about the five boroughs. Let's start with the simplest example and get the size of each borough population.

We will need to request the variable B01001_001E, which is the total population estimate. 

```{r echo=TRUE}
acs_boro_population <- getCensus(name = "acs/acs5",
                         vintage = 2018,
                         vars = c("NAME", "B01001_001E"),
                         region = "county:005,047,061,081,085",
                         regionin = "state:36" , key = myKey
                         )

acs_boro_population
```

Cool! We've established that we can pull some borough-level information from the US Census to complement data provided by the city or state. Note that the two tables, the one from NYC and the one from the census, don't exactly match up. For one thing, the county names do not align with the borough names.

#### Using named vectors as look-up tools {-}

Now, we can fix this by hand, but there are good ways and less good ways to do this. Ideally, we create a look-up table which we can reuse whenever we need to switch between borough and county names. For those familiar with database "join" operations, it is indeed possible to use joins in R. However, a simple way to just convert between two different representations (e.g., country name and borough name) is to use "named vectors" in R. Here's how:

```{r}
# Borough names
boroNames <- nyc_boro_data$BOROUGH_GROUP[1:5]
# County names
countyNames <- acs_boro_population$NAME

# combine, but note that the order is not the same! So we'll reorder
boro2county <- data.frame(Borough=boroNames, County=countyNames[c(5,2,3,1,4)], stringsAsFactors = FALSE)

# create two 'named vectors'
# one for getting the borough
getBoro <- boro2county$Borough
names(getBoro) <- boro2county$County

# one for getting the county
getCounty <- boro2county$County
names(getCounty) <- boro2county$Borough

```

Here's is one way we can use this new lookup table. Note that `getBoro` is not a function (it is a named vector). So we use square brackets to index it, not parentheses.

```{r}
getBoro["Richmond County, New York"]
getCounty["Brooklyn"]
```

```{r}
acs_boro_population$Borough <- getBoro[acs_boro_population$NAME]
acs_boro_population
```

All that remains is that annoying variable name B01001_001E for Total Population. We should definitely fix this, and there are a few ways to do it. The following may seem like a long-winded way to go about it, but it has the benefit that it will work no matter where the variable B01001_001E appears. It won't accidentally change the wrong column name, and it won't do anything at all if the variable you are trying to rename doesn't exist.

```{r}
names(acs_boro_population)[which(names(acs_boro_population)=="B01001_001E")] <- "TotalPop"
names(acs_boro_population)[which(names(acs_boro_population)=="NAME")] <- "countyName"
acs_boro_population
```

With this in hand, we can now combine our NYC COVID-19 data with our Census data. Recall 

```{r}
nyc_boro_data
```

We will make some judicious use of dplyr here to simplify the outcome. Mostly, we want to get rid of unnecessary columns from the ACS table (using `select`), and then use `join()` to merge the two tables.

```{r}
boro_join <- acs_boro_population %>% select(Borough, countyName, TotalPop) %>% 
  left_join(nyc_boro_data, by=c("Borough" =  "BOROUGH_GROUP"))
boro_join
```

Woohoo! (I'm keeping countyName for later. You'll see why.)

**Worked Example**: Compute the population adjusted rate per 100,000 people using population data from the census. How does it differ from the age-adjusted rate? 

We can use our population estimates (keep in mind that these are 5-year averages as of 2018) to derive our own rate-per-100,000 as follows

```{r}
boro_join$Rate2 <-  round(boro_join$COVID_CASE_COUNT/boro_join$TotalPop * 100000, 2)
boro_join
```

You'll notice that our rate, which is not age-adjusted, differs somewhat from the NYC rate, which is age-adjusted. Aside from age-adjustment, it is possible that our population numbers (based on 5-year averages) are different from the latest NYC populations estimates. If our population numbers are lower, then our rates would be higher. Or the difference could be a result of the age-adjustment formula.

#### More variables: income, age, and race {-}

To request the median household income we will request the variable "B19013_001E" (intuitive, right!) Alternatively, the variable B20017_001E is earnings per person not by household

```{r echo=TRUE}
acs_boro_income <- getCensus(name = "acs/acs5",
                         vintage = 2018,
                         vars = c("NAME", "B19013_001E", "B20017_001E"),
                         region = "county:005,047,061,081,085",
                         regionin = "state:36" , key = myKey
                         )

names(acs_boro_income)[which(names(acs_boro_income)=="B19013_001E")] <- "MedHHIncome"
names(acs_boro_income)[which(names(acs_boro_income)=="B20017_001E")] <- "MedIncome"
acs_boro_income
```
There it is, five-year averages, inflation-adjusted for 2018 dollars, by borough. (If you see one-year estimates, they may  be a bit higher than these numbers, if wages went up faster than inflation).

We can add these new income variables to the table we've started to build

```{r}

# Note that I am renaming NAME to countyName in the select(), so I didn't have to do it ahead of time
left_join(boro_join, 
          acs_boro_income %>% select(countyName=NAME, MedHHIncome, MedIncome), 
          by="countyName")

```

In the next part of the series, we will keep assembling more variables related to age and race. We will also change our unit of analysis to zipcode tabulation areas.
